**配置环境**
首先是配置环境（我是windows系统），下载完代码以后windows系统需要执行下面的命令（没有安装python环境的需要安装python环境，建议安装python3.6）：
    
    pip install ipython
    pip install jupyter
    pip install numpy
    pip install matplotlib

之后建议将下载下来的代码文件放在桌面上面，因为ipython不太好访问其他盘符，放在桌面是最好找的。环境配置好以后按win+R，输入

    ipython3 notebook # 因为是python3.6版本，所以这里要用ipython3而不是ipython notebook

进入到浏览器界面，打开knn.ipynb文件，依次执行代码（中间遇到报错的需要自己依次解决）

比如我自己下载的CIFAR-10文件路径不对，这里就需要根据打开的 cs231n\datasets\get_datasets.sh 文件中具体的路径（我这里是http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz）下载解压，放到dataset文件夹下面

执行到第6的代码块的时候，需要自己实现KNearestNeighbor

[这里](https://github.com/Tianji95/CS231n-Assignment-Solutions-Spring-2018/blob/master/assignment1/cs231n/classifiers/k_nearest_neighbor.py)是我的代码


**写代码过程中的笔记**
1. data_utils里面可以看出他们对源数据做了Normalize，具体在get_CIFAR10_data里面实现
2. KNN的two就不说了，one loop需要注意sum的时候axis=1，要不然加起来矩阵的方向是反的，no loop需要稍微思考一下矩阵运算，这里主要是要会用numpy的broadcast sum
+ [这里是broadcast sum的官方文档](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)
+ [以及一个Stack Overflow](https://stackoverflow.com/questions/27948363/numpy-broadcast-to-perform-euclidean-distance-vectorized?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)
3. predict_labels里面要注意bincount和argmax的使用
